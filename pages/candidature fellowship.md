- https://umfrage.algorithmwatch.org/third-reporting-fellowship/
	- submitted proposal
	  collapsed:: true
		- contribution {{renderer :wordcountchar_}}
			- I am willing to work on failures of automated decisions systems with a focus on social scoring implementations. Methods will be
				- retro-engineering of machine learning and statistical inference pieces of software. Looking forward to the management of missing or erroneous data
				- observations and interviews with public agents using outputs of scoring systems
				- field interviews of citizens having suffered from the effects of errors of classification, false positive detection, or automated allocation
				- field interviews of civil society actors trying to prevent misallocation or to bridge the digital gap leading to usability problems with the administration
				- analysis of socio-economic data related to the activities of public administrations
				- field interviews of civil society actors promoting a critical rethinking of technological interfaces between public administrations and citizens
				- scrapping and transforming data from websites and official public datasets to produce visualizations and insights
		- reporting plan {{renderer :wordcountchar_}}
			- write a report about existing and reported failures of automated decisions and their impact on people already in situations of poverty. Broaden the perspective to other European countries. idea is that control is inducing a shift from social security to social insecurity
			- meet following orgs
				- Changer de cap
				- La Quadrature du Net
				- Nos services publics
				- La MedNum
				- Défenseur des Droits
				- CNIL
				- CADA
			- write a report about a typology of failures of automated decision systems
			- develop a network of sources within public organizations
			- scrap data about Maisons France Services
			- write a report about the cognitive dissonance between the surveillance background of social scoring and a basic concept of trust between public institutions and citizens
			- write a report about a long-term history of computerization, political elites and the ambivalence of technology as a mean to improve quality of relationship between citizen and welfare state
		- looking for {{renderer :wordcountchar_}}
			- expert look on reporting and writing. I think I know how to write but I might sometimes have a militant point of view that won't satisfy basic journalist reporting standard
			- knowledge on local variants of EC legislation. Like implementations of GDPR, right to document access, etc
			- existing public datasets in other EC countries
	-
	- {{renderer :wordcountchar_}}
		- I am willing to investigate on social scoring in french social security institutions. I want to focus on errors of algoritms both as results and as inputs. My main intuition is that the right to errors is not compatible with surveillance and machine learning.
	- > I am willing to investigate on causes and consequences of errors within automated decision process in Caisse Nationale des Assurances Familliales, the French public administration whose task is to .
	  First there is the relation between the labelling of usability and digital litteracy issues as "errors" or "mistakes" and marginalized and discriminated subpopulations. There is a right to mistake, "droit à l'erreur", in the French legislation but its implementation are far from being generous or even effecient. The intention of this law is to restore trust and confidence between citizens and public institutions, mainly financial and social ones.
	  Second there is the wide range of errors in automated decisions that can be caused by software issues, dirty datasets or misinterpretation of user inputs. How are these errors are handled and by whom? Who is penalized or suffers from financial pressure by those errors?
	  > I would like to link the two levels and write stories on the fundamental contradiction between "droit à l'erreur" and underlooked surveillance apparatus deployed by social scoring algorithms.
	  > There is currently also a strong momentum as this kind of thinking is popular among technocratic elites.
	  > 
	  > I will also be happy to provide strong support with data analysis/science with fairness evaluation or understanding of source code.
- ## deadline
	- `12.11.2023`
	- > The deadline to apply is Sunday, 12 November 23:59 CET (find below the application form).
- ## q&a
	- `17.10`
	- `20.10`
	- > We will be holding two Q&A session on Zoom to solve doubts and further questions on [October 17th at 11:00 CET](https://eu01web.zoom.us/j/61377466649?pwd=VkpCZkM5dWlneXdRSWI5TTZiRHJqZz09) and on [October 20th at 19:00 CET](https://eu01web.zoom.us/j/66881624854?pwd=MDA4ZkhiQzlvL0JMVUFpZ29NNWZwdz09).
- ## topics
	- > What we are planning to report on: 
	  >
	  >* Algorithms ― based or not on AI ― used by financial institutions and other agents (banks, insurance companies, budget-tracking apps, loans and microcredit entities, ministerial departments and public administrations, etc.)
	  >* The impact on specific groups of these automated systems, such as inhabitants of selected neighborhoods having credits denied or exiled people who cannot access public subsidies.
	  >* Unpublished data used to implement, support and run the automated systems used by these institutions, i.e. databases, bibliography used in the design of the system, internal or independent audits, false positive and negative rates, etc.
	  >* Ideally, human-centered stories and interviews that include people affected by the use of these programs and their consequences.
	  >* Current situation or updates on the regulation that affects such systems and their use upon the general population.
- ## questions
	- What would you contribute to a research on automated discrimination by financial institutions in Europe?
		- > For example: Gather data on insurance premiums to analyze how they vary for subgroups in a specific country, ask specific people to request their personal data under Art. 15 GDPR and check for patterns, interview industry insiders about their practices, talk to people who’ve had their credit turned down… If you’re unsure about your idea, do send us an e-mail at kayser-bril@algorithmwatch.org.
		- ### draft
			- documenter les erreurs d'automatisation des décisions administratives concernant les aides sociales sur le quotidien des bénéficiaires
				- réalité du droit à l'erreur
					- Qu'est-ce qui se passe quand un algorithme se trompe ?
					- parcours de réparation
					- Est-ce que c'est égalitaire ?
				- faire une enquête de terrain sur les "maisons France Services"
					- analyser les données. par exemple la géographie
				- contacter et interviewer les associations et entreprises sociales gravitant autour de la solidarité et de l'inclusion numérique pour documenter la mise en périphérie de l'accompagnement au profit d'un discours sur l'innovation et la technocratie
				- contacter et interviewer des experts sur le non-recours pour construire une histoire autour de la non-automatisation complète du versement des prestations sociales
				- enquêter sur les entreprises prédatrices profitant du manque d'accessibilité des démarches administratives
				-
			- I would like to interview industry insiders, specifically tech people hired by public institutions to either implement data sciences or in-house data analysts and data scientists contributing automation and generalization of algorithms.
				- il y a deux sociologies
					- celles des travailleurs de la technique qui construisent les systèmes d'informatisation et d'automatisation des démarches administratives. dépôt et prise de décision
					- et celle des administrés et des personnes à qui s'adressent les démarches
				- le sujet du fellowship est le risque de discriminations introduit par l'informatisation et l'automatisation des démarches fiscales. On peut aussi parler des demandes d'aide.
				- aides aux entreprises concernent à la fois des grosses entreprises que des auto-entrepreneurs.
				- charge de travail administrative n'est pas la même.
				- inégalités et discrimination. question de pouvoir et de domination.
				- mes aides vs entreprises prédatrices. législation et protection des citoyens.
					- utilité pour l'administration https://leximpact.an.fr/
				- parcoursup et services privés de préparation
			- I would also like to work with good willing citizens helping less tech savy people to perform administrative tasks. There is also the new public work force dedicated to this effort.
			- My general aim is to describe the widening digital gap induced by the French technocracy.
			- Modernization
			- Automation
			- Computerization
				- risks for whom
				- why is it a thing
				- power and elites
			- Computer-aided technology
			- Smartphone
			- Knowledge
			- Platform capitalism
			- transparence
				- https://publi.codes/
				- quels sont les publics ?
				- ancrages institutionnels ? décalage stratégique ? portage politique ?
			- https://www.pimmsmediation.fr/
			- https://www.economie.gouv.fr/particuliers/france-services
			- https://changerdecap.net/petition-caf/
			- https://nosservicespublics.fr/
	- What would be your research plan and intermediate steps?
		- ### draft
	- What would you need from other fellows?
		- > For example: I’m planning to do a statistical analysis on credit scores; I’d need another fellow to interview people on the ground to verify my findings.
		- ### draft
			- états des lieux sur la législation européenne concernant la protection des citoyens, la justice sociale et les initiatives de réduction du digital gap
			- comparaison avec d'autres pays sur les structures de pouvoir et les intérêts particulier à l'informatisation
			- écriture journalistique et storytelling
	- Would you need an extra budget to carry out your research? Please list each item of expenditure and its cost.
-
- https://github.com/taniki/assemblee-nationale
	- https://data.11d.im/foodcourt/votes-an/pca-deputes
	- DONE ajouter un `readme`
- https://observablehq.com/@taniki/regionales2021-sondages-ecarts?collection=%40taniki%2Felections-regionales-france-2021
	- DONE vérifier que c'est compréhensible à première vue